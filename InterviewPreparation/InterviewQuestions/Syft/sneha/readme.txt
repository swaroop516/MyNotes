Question-
https://github.com/Syft-Application/data-eng-coding-challenge



Note-
1. Code has developed and executed in python version 3.9.0
2. Code has developed in python framework pandas. However it can be done in native python also. 
Pandas code can be migrate to Spark/SQL with minimal changes.
3. This code has designed to execute in batch load. For streaming minimal changes are required.
4. We can store data in any columnar database with right indexing. 
5. If the data is large-scale in storage and processing. We can store in AWS s3, Azure blob, GCS for storage. 
For processing, we can use spark. In terms type of storage, parquet suits best as it is columnar oriented. 
